# EstratÃ©gia de Rate Limiting e Riscos

## âš ï¸ O que acontece se formos bloqueados pela VTEX?

### ConsequÃªncias do Bloqueio:

#### 1. **HTTP 429 - Too Many Requests**
**O que acontece:**
- VTEX retorna `429 Too Many Requests`
- Todas as requests subsequentes falham por 1-5 minutos
- **NÃƒO Ã© permanente** - Ã© um bloqueio temporÃ¡rio

**Impacto:**
- âœ… **Baixo**: A API VTEX NÃƒO bloqueia permanentemente
- â±ï¸ **DuraÃ§Ã£o**: 1-5 minutos tÃ­picos
- ğŸ”„ **Recovery**: AutomÃ¡tico apÃ³s o perÃ­odo de cooldown

#### 2. **Rate Limit ViolaÃ§Ã£o (5,000 req/min)**
**O que acontece:**
- VTEX throttles requests acima de 5,000/min
- Requests adicionais retornam `429` ou `503`
- Pode afetar **TODOS os stores** na mesma conta VTEX (se compartilharem conta)

**Impacto:**
- âš ï¸ **MÃ©dio**: Afeta todas as aplicaÃ§Ãµes usando a mesma conta
- ğŸ• **DuraÃ§Ã£o**: AtÃ© prÃ³xima janela de 60 segundos
- ğŸ’¡ **MitigaÃ§Ã£o**: Rate limiter global compartilhado

#### 3. **IP Ban (RARO)**
**O que acontece:**
- Apenas se detectarem padrÃ£o malicioso (ex: 100,000 req/min sustentado)
- VTEX raramente faz IP ban por scraping legÃ­timo
- Mais comum em ataques DDoS

**Impacto:**
- âŒ **Alto**: Bloqueio do IP por horas/dias
- ğŸ”¥ **Probabilidade**: < 0.1% se usarmos rate limiter
- ğŸ›¡ï¸ **PrevenÃ§Ã£o**: Nosso rate limiter evita isso

---

## ğŸ›¡ï¸ Nossa EstratÃ©gia de MitigaÃ§Ã£o

### 1. **Rate Limiter com Token Bucket**

ImplementaÃ§Ã£o: [`src/ingest/scrapers/rate_limiter.py`](src/ingest/scrapers/rate_limiter.py)

```python
# Limites conservadores (80% da capacidade VTEX)
rate_limiter = RateLimiter(
    rate_limit=4000,        # 80% de 5,000 (margem de seguranÃ§a)
    window_seconds=60,      # Janela de 1 minuto
    max_concurrent=80       # 80% de 100 (evita burst excessivo)
)
```

**Por que 80% e nÃ£o 100%?**
- âœ… Margem para outras aplicaÃ§Ãµes na mesma conta
- âœ… ProteÃ§Ã£o contra variaÃ§Ãµes de relÃ³gio (clock skew)
- âœ… Buffer para retries em caso de erros

### 2. **Exponential Backoff em 429**

Quando recebemos `429`, aplicamos backoff exponencial:

```python
# Implementado em _scrape_by_ids_parallel
try:
    resp = session.get(api_url, params=params, timeout=20)
    if resp.status_code == 429:
        retry_count += 1
        wait_time = min(2 ** retry_count, 60)  # Max 60s
        logger.warning(f"Rate limited, waiting {wait_time}s")
        time.sleep(wait_time)
except:
    # Handle retries
```

**Tentativas:**
1. Erro 429 â†’ espera 2s
2. Erro 429 â†’ espera 4s
3. Erro 429 â†’ espera 8s
4. Erro 429 â†’ espera 16s
5. Erro 429 â†’ espera 32s
6. Erro 429 â†’ espera 60s (max)

### 3. **Global Rate Limiter (Compartilhado)**

**Problema:** Se scrapers mÃºltiplos rodam em paralelo (bistek + fort + giassi), cada um pode tentar usar 5,000 req/min, totalizando 15,000 req/min!

**SoluÃ§Ã£o:** Rate limiter **global** compartilhado entre todos os stores:

```python
# Em rate_limiter.py
_global_rate_limiter = None  # Singleton

def get_rate_limiter():
    global _global_rate_limiter
    if _global_rate_limiter is None:
        _global_rate_limiter = RateLimiter(
            rate_limit=4000,  # 80% of 5000
            window_seconds=60,
            max_concurrent=80
        )
    return _global_rate_limiter
```

Todos os scrapers compartilham o **mesmo token bucket**, garantindo:
- âœ… Total de requests < 4,000/min (todos os stores combinados)
- âœ… Concurrent requests < 80 (todos os stores combinados)

### 4. **Monitoramento em Tempo Real**

Durante scraping, podemos monitorar taxa atual:

```python
stats = rate_limiter.get_stats()
# {
#   "current_rate": 2500,              # req/min atual
#   "requests_in_window": 2500,        # requests nos Ãºltimos 60s
#   "rate_limit": 4000,                # limite configurado
#   "max_concurrent": 80,              # max threads
#   "available_concurrent": 45         # slots disponÃ­veis
# }
```

Se `current_rate` > 3500 (87.5%), podemos adicionar delays extras automaticamente.

---

## ğŸ“Š CenÃ¡rios de Teste

### CenÃ¡rio 1: Agressivo Seguro (Nossa Config)
```yaml
request_delay: 0.1s
max_workers: 13 (regiÃµes em paralelo)
rate_limit: 4000/min (80% da capacidade)
```

**Resultado esperado:**
- âœ… **Requests/min**: ~3,000-3,500 (dentro do limite)
- âœ… **Concurrent**: ~50-70 threads (dentro do limite)
- âœ… **Probabilidade 429**: < 1%
- âš¡ **Speedup**: ~20-30x vs sequencial

**Tempo estimado:**
- Bistek: 65 min â†’ **~2-3 min**
- Fort: 56 min â†’ **~2 min**
- Giassi: 102 min â†’ **~4-5 min**

### CenÃ¡rio 2: MUITO Agressivo (NÃƒO RECOMENDADO)
```yaml
request_delay: 0s
max_workers: 50
rate_limit: 5000/min (100% da capacidade)
```

**Resultado esperado:**
- âš ï¸ **Requests/min**: 4,500-5,500 (excede limite!)
- âš ï¸ **Concurrent**: 90-110 threads (excede burst!)
- âŒ **Probabilidade 429**: 30-50%
- ğŸ”¥ **Risco IP ban**: 5-10%

**Por que NÃƒO fazer:**
- âŒ Muitos erros 429 â†’ desperdÃ­cio de tempo em retries
- âŒ Afeta outros scrapers na mesma conta
- âŒ Pode triggar proteÃ§Ã£o anti-bot da VTEX

### CenÃ¡rio 3: Ultra Conservador (Atual)
```yaml
request_delay: 0.5s
max_workers: 1 (sequencial)
rate_limit: N/A
```

**Resultado esperado:**
- âœ… **Probabilidade 429**: ~0%
- â±ï¸ **Speedup**: 1x (baseline)
- ğŸ’¤ **DesperdÃ­cio**: 95% da capacidade nÃ£o utilizada

---

## ğŸ¯ RecomendaÃ§Ãµes

### Para Scraping DiÃ¡rio (ProduÃ§Ã£o):
```yaml
# config/stores.yaml
request_delay: 0.1      # 3x faster que 0.3s
max_workers: 10         # Paralelo agressivo mas seguro
```

**Rate limiter:**
```python
RateLimiter(
    rate_limit=4000,    # 80% da capacidade (seguro)
    max_concurrent=80   # 80% do burst (seguro)
)
```

**Resultado:**
- âœ… Seguro (<1% chance de 429)
- âš¡ ~20x mais rÃ¡pido
- ğŸ›¡ï¸ Margem para outros scrapes/apps

### Para Scraping One-off (Urgente):
```yaml
request_delay: 0.05     # 6x faster que 0.3s
max_workers: 15         # Muito agressivo
```

**Rate limiter:**
```python
RateLimiter(
    rate_limit=4500,    # 90% da capacidade (arriscado)
    max_concurrent=90   # 90% do burst (arriscado)
)
```

**Resultado:**
- âš ï¸ Moderado (5-10% chance de 429)
- âš¡ ~30x mais rÃ¡pido
- ğŸ”¥ Use apenas quando necessÃ¡rio

### Para Desenvolvimento/Teste:
```yaml
request_delay: 0.2      # Conservador
max_workers: 3          # Baixo paralelismo
```

**Resultado:**
- âœ… Muito seguro
- â±ï¸ ~5x mais rÃ¡pido
- ğŸ§ª Bom para debug

---

## ğŸ” Como Detectar se Fomos Bloqueados

### Logs para Monitorar:

```bash
# Verificar erros 429 em tempo real
tail -f data/logs/app.log | grep "429"

# Verificar rate limiter stats
tail -f data/logs/app.log | grep "rate_limiter_stats"
```

### MÃ©tricas no DuckDB:

```sql
-- Contagem de erros por status code
SELECT
    api_status_code,
    COUNT(*) as count,
    AVG(response_time_ms) as avg_ms
FROM scraper_batches
WHERE run_id = 'bistek_20260205_120000'
GROUP BY api_status_code
ORDER BY count DESC;

-- Se ver muitos 429, fomos agressivos demais!
```

### Sinais de Problema:

| Sinal | Significado | AÃ§Ã£o |
|-------|------------|------|
| 1-5 erros 429 | Normal, retry automÃ¡tico OK | âœ… Nada |
| 10-20 erros 429 | Perto do limite, precauÃ§Ã£o | âš ï¸ Reduzir max_workers |
| 50+ erros 429 | Bloqueio ativo, muito agressivo | âŒ Cancelar e esperar 5 min |
| 503 sustained | VTEX em manutenÃ§Ã£o ou overload | ğŸ›‘ Esperar 30-60 min |

---

## ğŸš€ PrÃ³ximos Passos (OtimizaÃ§Ãµes Futuras)

### 1. **Adaptive Rate Limiting**
Ajustar rate automaticamente baseado em taxa de erro:
- Se 429 rate < 1%: aumentar rate_limit em 10%
- Se 429 rate > 5%: diminuir rate_limit em 20%
- Se 429 rate > 20%: pause por 60s

### 2. **Circuit Breaker**
Se muitos erros 429 consecutivos, pausar temporariamente:
```python
if consecutive_429_errors > 10:
    logger.warning("Circuit breaker: pausing 60s")
    time.sleep(60)
```

### 3. **Distributed Rate Limiting**
Se rodarmos scrapers em mÃºltiplas mÃ¡quinas:
- Redis para compartilhar token bucket
- CoordenaÃ§Ã£o central de rate limit

---

## ğŸ“ ConclusÃ£o

**Nossa estratÃ©gia atual (80% da capacidade) Ã©:**
- âœ… **Segura**: <1% chance de bloqueio
- âš¡ **RÃ¡pida**: 20-30x speedup vs sequencial
- ğŸ›¡ï¸ **Defensiva**: Margem para outras apps
- ğŸ¯ **Ideal para produÃ§Ã£o**

**Se precisar mais velocidade:**
- Aumentar para 90% da capacidade (4,500 req/min)
- Aceitar 5-10% de erros 429 (com retry automÃ¡tico)
- **NÃ£o** exceder 95% (muito arriscado)

**NUNCA:**
- âŒ Desabilitar rate limiter
- âŒ Usar 100% da capacidade sustentado
- âŒ Ignorar erros 429 sem backoff

---

**Ãšltima atualizaÃ§Ã£o**: 2026-02-05
**VersÃ£o**: 1.0 (Performance Optimization - Phase 3)
