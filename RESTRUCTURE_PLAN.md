# Project Restructure Plan

## Current Issues

### 1. Files in Root (should be in src/ or scripts/)
- `app.py` â†’ Dashboard entry point (duplicate of `src/dashboard/app.py`)
- `prefect_cloud_runner.py` â†’ Orchestration script
- `run_scraper_standalone.py` â†’ Standalone scraper runner

### 2. Documentation Scattered
- `OPTIMIZATION_GUIDE.md` â†’ Move to `docs/operations/`
- `PREFECT_CLOUD_SETUP.md` â†’ Move to `docs/operations/`
- `STREAMLIT_DEPLOY.md` â†’ Move to `docs/deployment/`
- `SETUP.md` â†’ Keep in root (initial setup)
- `CHANGELOG.md` â†’ Keep in root
- `CONTRIBUTING.md` â†’ Keep in root
- `CONTRIBUTORS.md` â†’ Keep in root

### 3. Junk Files
- `azure_analytics_url.txt` â†’ DELETE
- `reseach.txt` â†’ DELETE (typo in name!)
- `nul` â†’ DELETE (Windows artifact)
- `requirements_dashboard.txt` â†’ DELETE (use `requirements.txt`)

### 4. Legacy Data (11GB JSONL)
- `archive/legacy_scrapers/bistek_products_scraper/` (6.4GB)
- `archive/legacy_scrapers/fort_products_scraper/` (1.7GB)
- `archive/legacy_scrapers/giassi_products_scraper/` (3.3GB)
- `archive/legacy_scrapers/bad_angeloni_products_scraper/` (20KB - corrupted)

**Action**: Migrate to Parquet, then delete archive/

---

## New Structure

```
market_scraper/
â”œâ”€â”€ src/                          # Source code
â”‚   â”œâ”€â”€ cli/                      # Command-line interfaces
â”‚   â”‚   â”œâ”€â”€ scraper.py           # Main CLI for scraping (from scripts/cli.py)
â”‚   â”‚   â”œâ”€â”€ enrichment.py        # EAN enrichment CLI (from scripts/cli_enrich.py)
â”‚   â”‚   â”œâ”€â”€ validation.py        # Data validation CLI (from scripts/cli_validate_deals.py)
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ dashboard/                # Streamlit dashboards
â”‚   â”‚   â”œâ”€â”€ app.py               # Main dashboard (KEEP THIS ONE)
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚
â”‚   â”œâ”€â”€ ingest/                   # Data ingestion
â”‚   â”‚   â”œâ”€â”€ scrapers/            # Scraper implementations
â”‚   â”‚   â””â”€â”€ loaders/             # Data loaders
â”‚   â”‚
â”‚   â”œâ”€â”€ orchestration/            # Prefect workflows
â”‚   â”‚   â”œâ”€â”€ scraper_flow.py      # Main scraper flow
â”‚   â”‚   â”œâ”€â”€ analytics_flow.py    # Analytics flow
â”‚   â”‚   â”œâ”€â”€ delta_sync_flow.py   # OpenFoodFacts sync
â”‚   â”‚   â””â”€â”€ runner.py            # Runner for Prefect Cloud (from prefect_cloud_runner.py)
â”‚   â”‚
â”‚   â”œâ”€â”€ analytics/                # Analytics engine
â”‚   â”œâ”€â”€ enrichment/               # Data enrichment
â”‚   â”œâ”€â”€ observability/            # Logging, metrics
â”‚   â”œâ”€â”€ schemas/                  # Pydantic models
â”‚   â””â”€â”€ transform/                # DBT project
â”‚
â”œâ”€â”€ scripts/                      # Utility scripts
â”‚   â”œâ”€â”€ deployment/               # Deployment automation
â”‚   â”‚   â”œâ”€â”€ deploy_to_cloud.sh
â”‚   â”‚   â”œâ”€â”€ deploy_to_cloud.ps1
â”‚   â”‚   â”œâ”€â”€ deploy_to_cloud_free_tier.ps1
â”‚   â”‚   â”œâ”€â”€ start_prefect_server.ps1
â”‚   â”‚   â”œâ”€â”€ stop_prefect_server.ps1
â”‚   â”‚   â””â”€â”€ start_prefect.bat
â”‚   â”‚
â”‚   â”œâ”€â”€ maintenance/              # Maintenance tasks
â”‚   â”‚   â”œâ”€â”€ check_old_scraper.py
â”‚   â”‚   â”œâ”€â”€ check_running_scraper.py
â”‚   â”‚   â”œâ”€â”€ migrate_legacy_data.py  # NEW: Data migration script
â”‚   â”‚   â””â”€â”€ validate_hot_deals_quality.py
â”‚   â”‚
â”‚   â”œâ”€â”€ monitoring/               # Monitoring tools
â”‚   â”‚   â”œâ”€â”€ monitor_scrape.py
â”‚   â”‚   â””â”€â”€ check_progress.sh
â”‚   â”‚
â”‚   â”œâ”€â”€ setup/                    # Setup automation
â”‚   â”‚   â”œâ”€â”€ setup_prefect_cloud_startup.ps1
â”‚   â”‚   â”œâ”€â”€ setup_startup_task.ps1
â”‚   â”‚   â”œâ”€â”€ daily_delta_sync.ps1
â”‚   â”‚   â”œâ”€â”€ daily_delta_sync.bat
â”‚   â”‚   â””â”€â”€ install_task_scheduler.ps1
â”‚   â”‚
â”‚   â””â”€â”€ azure/                    # Azure utilities
â”‚       â”œâ”€â”€ upload_analytics_to_azure.py
â”‚       â””â”€â”€ update_streamlit.py
â”‚
â”œâ”€â”€ docs/                         # Documentation
â”‚   â”œâ”€â”€ architecture/
â”‚   â”œâ”€â”€ development/
â”‚   â”œâ”€â”€ quality/
â”‚   â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ operations/               # NEW: Operational guides
â”‚   â”‚   â”œâ”€â”€ OPTIMIZATION_GUIDE.md     # From root
â”‚   â”‚   â””â”€â”€ PREFECT_CLOUD_SETUP.md    # From root
â”‚   â””â”€â”€ deployment/               # NEW: Deployment guides
â”‚       â””â”€â”€ STREAMLIT_DEPLOY.md       # From root
â”‚
â”œâ”€â”€ data/                         # Data storage (gitignored)
â”‚   â”œâ”€â”€ bronze/
â”‚   â”œâ”€â”€ silver/
â”‚   â”œâ”€â”€ gold/
â”‚   â”œâ”€â”€ logs/
â”‚   â””â”€â”€ metrics/
â”‚
â”œâ”€â”€ config/                       # Configuration files
â”‚   â””â”€â”€ stores.yaml
â”‚
â”œâ”€â”€ tests/                        # Test suite
â”‚   â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ integration/
â”‚   â””â”€â”€ e2e/
â”‚
â”œâ”€â”€ pages/                        # Streamlit pages (keep for backward compatibility)
â”‚   â”œâ”€â”€ 1_ğŸ’°_AnÃ¡lise_de_PreÃ§os.py
â”‚   â”œâ”€â”€ 2_ğŸ·ï¸_AnÃ¡lise_de_PromoÃ§Ãµes.py
â”‚   â””â”€â”€ 3_ğŸ¥Š_Competitividade.py
â”‚
â”œâ”€â”€ .github/                      # GitHub configuration
â”œâ”€â”€ .streamlit/                   # Streamlit config
â”œâ”€â”€ README.md                     # Project overview
â”œâ”€â”€ CLAUDE.md                     # Project instructions
â”œâ”€â”€ SETUP.md                      # Initial setup guide
â”œâ”€â”€ CHANGELOG.md                  # Version history
â”œâ”€â”€ CONTRIBUTING.md               # Contribution guide
â”œâ”€â”€ CONTRIBUTORS.md               # Contributors list
â”œâ”€â”€ LICENSE                       # License
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ Dockerfile                    # Container definition
â”œâ”€â”€ prefect.yaml                  # Prefect configuration
â””â”€â”€ pytest.ini                    # Pytest configuration
```

---

## Migration Steps

### Phase 1: Cleanup Junk
```bash
# Delete junk files
rm azure_analytics_url.txt reseach.txt nul requirements_dashboard.txt
```

### Phase 2: Reorganize Scripts
```bash
# Create new directories
mkdir -p scripts/{deployment,maintenance,monitoring,setup,azure}
mkdir -p src/cli
mkdir -p docs/{operations,deployment}

# Move deployment scripts
mv deploy_to_cloud.sh deploy_to_cloud.ps1 deploy_to_cloud_free_tier.ps1 scripts/deployment/
mv scripts/start_prefect_server.ps1 scripts/stop_prefect_server.ps1 scripts/start_prefect.bat scripts/deployment/

# Move maintenance scripts
mv scripts/check_old_scraper.py scripts/check_running_scraper.py scripts/maintenance/
mv scripts/validate_hot_deals_quality.py scripts/maintenance/

# Move monitoring scripts
mv scripts/monitor_scrape.py scripts/check_progress.sh scripts/monitoring/

# Move setup scripts
mv scripts/setup_prefect_cloud_startup.ps1 scripts/setup_startup_task.ps1 scripts/setup/
mv scripts/daily_delta_sync.ps1 scripts/daily_delta_sync.bat scripts/install_task_scheduler.ps1 scripts/setup/

# Move Azure scripts
mv scripts/upload_analytics_to_azure.py scripts/update_streamlit.py scripts/azure/

# Move CLIs to src/cli/
mv scripts/cli.py src/cli/scraper.py
mv scripts/cli_enrich.py src/cli/enrichment.py
mv scripts/cli_validate_deals.py src/cli/validation.py

# Move investigation script (temporary, can be deleted later)
mv scripts/investigate_carrefour_api.py scripts/maintenance/
```

### Phase 3: Move Root Files
```bash
# Remove duplicate dashboard entry point (keep src/dashboard/app.py)
rm app.py

# Move orchestration files
mv prefect_cloud_runner.py src/orchestration/runner.py
mv run_scraper_standalone.py src/orchestration/standalone_runner.py
```

### Phase 4: Move Documentation
```bash
# Move operational guides
mv OPTIMIZATION_GUIDE.md docs/operations/
mv PREFECT_CLOUD_SETUP.md docs/operations/

# Move deployment guides
mv STREAMLIT_DEPLOY.md docs/deployment/
```

### Phase 5: Migrate Legacy Data
```bash
# Dry run first
python scripts/migrate_legacy_data.py --store all --dry-run

# Actual migration (can take 10-30 minutes)
python scripts/migrate_legacy_data.py --store all

# Validate migrated data
python src/cli/scraper.py validate-bronze --store bistek
python src/cli/scraper.py validate-bronze --store fort
python src/cli/scraper.py validate-bronze --store giassi

# Once validated, delete archive
rm -rf archive/
```

---

## Code Changes Required

### 1. Update imports in all files
- `from scripts.cli import` â†’ `from src.cli.scraper import`
- `from scripts.cli_enrich import` â†’ `from src.cli.enrichment import`

### 2. Update Prefect flows
- `prefect_cloud_runner.py` references â†’ `src.orchestration.runner`

### 3. Update Streamlit config
- `.streamlit/config.toml`: Ensure it points to `src/dashboard/app.py`

### 4. Update GitHub workflows
- `.github/workflows/*`: Update paths if they reference moved files

### 5. Update documentation
- All `docs/*.md`: Update paths to reflect new structure

---

## Validation Checklist

After restructure, validate:

- [ ] All scrapers run: `python src/cli/scraper.py scrape bistek --limit 100`
- [ ] Enrichment works: `python src/cli/enrichment.py stats`
- [ ] Dashboard loads: `streamlit run src/dashboard/app.py`
- [ ] Prefect flows work: `python src/orchestration/runner.py`
- [ ] Tests pass: `pytest tests/`
- [ ] DBT runs: `cd src/transform/dbt_project && dbt run`
- [ ] No broken imports: `python -m py_compile **/*.py`

---

## Benefits

1. **Cleaner root**: Only essential files (README, LICENSE, config)
2. **Logical grouping**: Scripts organized by purpose (deployment, maintenance, monitoring)
3. **Better discoverability**: Clear separation between CLI, orchestration, and dashboard
4. **Smaller footprint**: 11GB archive deleted after migration
5. **Standard structure**: Follows Python project best practices