# Prefect deployment configuration
# This file configures deployments to run from local code without git clone

# Build step - nothing needed for local code
build: []

# Push step - nothing to push for local code
push: []

# Pull step - EMPTY to use local code directly (no git clone)
pull: []

# Deployments
deployments:
  # ──────────────────────────────────────────────────────────────────────
  # MAIN PIPELINE (Recommended - runs everything end-to-end)
  # ──────────────────────────────────────────────────────────────────────
  - name: daily-pipeline
    version: null
    tags: [production, main-pipeline]
    description: "Complete data platform pipeline: Ingestão → Enriquecimento → Transformação → Disponibilização"
    schedule:
      cron: "0 1 * * *"  # 1:00 AM daily
      timezone: America/Sao_Paulo
    entrypoint: src/orchestration/daily_pipeline_flow.py:daily_pipeline_flow
    parameters: {}
    work_pool:
      name: market-scraper-pool

  # ──────────────────────────────────────────────────────────────────────
  # INDIVIDUAL FLOWS (For ad-hoc execution or testing)
  # ──────────────────────────────────────────────────────────────────────

  # Scraping flow (can run independently)
  - name: daily-scraper
    version: null
    tags: [scraping, ingestao]
    description: "Scraping of all supermarket stores (parallel execution)"
    schedule: null  # No auto-schedule (use main pipeline or manual trigger)
    entrypoint: src/orchestration/scraper_flow.py:daily_scraper_flow
    parameters: {}
    work_pool:
      name: market-scraper-pool

  # OpenFoodFacts enrichment flow (can run independently)
  - name: daily-delta-sync
    version: null
    tags: [enrichment, openfoodfacts]
    description: "OpenFoodFacts delta sync with DBT updates"
    schedule: null  # No auto-schedule (use main pipeline or manual trigger)
    entrypoint: src/orchestration/delta_sync_flow.py:daily_delta_sync_flow
    parameters: {}
    work_pool:
      name: market-scraper-pool

  # DBT transformation flow (can run independently)
  - name: daily-transform
    version: null
    tags: [transform, dbt]
    description: "DBT transformations (bronze → silver → gold) with data quality testing"
    schedule: null  # No auto-schedule (use main pipeline or manual trigger)
    entrypoint: src/orchestration/transform_flow.py:daily_transform_flow
    parameters: {}
    work_pool:
      name: market-scraper-pool

  # Analytics and reporting flow (can run independently)
  - name: daily-analytics
    version: null
    tags: [analytics, reporting]
    description: "Analytics, reporting, and data export"
    schedule: null  # No auto-schedule (use main pipeline or manual trigger)
    entrypoint: src/orchestration/analytics_flow.py:daily_analytics_flow
    parameters: {}
    work_pool:
      name: market-scraper-pool
