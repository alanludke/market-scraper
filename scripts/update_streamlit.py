"""
Update Streamlit Cloud Dashboard - Automated Pipeline

This script automates the complete flow to update Streamlit Cloud data:
1. Run DBT transformations (bronze â†’ trusted â†’ marts)
2. Upload analytics.duckdb to Azure Blob Storage
3. Generate new SAS URL (valid 1 year)
4. Display instructions to update Streamlit secret

Usage:
    python scripts/update_streamlit.py

    # Skip DBT (if already ran)
    python scripts/update_streamlit.py --skip-dbt

    # Only run DBT (no upload)
    python scripts/update_streamlit.py --dbt-only

Requirements:
    - DBT project configured (src/transform/dbt_project/)
    - Azure credentials in .env (AZURE_ACCOUNT_NAME, AZURE_ACCOUNT_KEY)
    - analytics.duckdb exists (generated by DBT)
"""

import argparse
import subprocess
import sys
from datetime import datetime
from pathlib import Path

from dotenv import load_dotenv

load_dotenv()


def run_command(cmd: list[str], cwd: Path | None = None) -> bool:
    """Run shell command and return success status."""
    print(f"\n{'â”€' * 60}")
    print(f"Running: {' '.join(cmd)}")
    print(f"{'â”€' * 60}\n")

    try:
        result = subprocess.run(
            cmd,
            cwd=cwd,
            check=True,
            text=True,
            capture_output=False,  # Show output in real-time
        )
        return result.returncode == 0
    except subprocess.CalledProcessError as e:
        print(f"\nâŒ Command failed with exit code {e.returncode}")
        return False


def run_dbt() -> bool:
    """Run DBT transformations."""
    print("\n" + "=" * 60)
    print("ğŸ”„ STEP 1: Running DBT Transformations")
    print("=" * 60)

    dbt_dir = Path("src/transform/dbt_project")
    if not dbt_dir.exists():
        print(f"âŒ DBT directory not found: {dbt_dir}")
        return False

    # Run all DBT models
    success = run_command(["dbt", "run"], cwd=dbt_dir)

    if success:
        # Check analytics.duckdb exists and is recent
        db_path = Path("data/analytics.duckdb")
        if db_path.exists():
            age_seconds = (datetime.now() - datetime.fromtimestamp(db_path.stat().st_mtime)).seconds
            size_mb = db_path.stat().st_size / 1024 / 1024
            print(f"\nâœ… analytics.duckdb generated successfully")
            print(f"   Size: {size_mb:.1f} MB")
            print(f"   Age: {age_seconds}s ago")
        else:
            print(f"\nâš ï¸  Warning: analytics.duckdb not found at {db_path}")
            return False

    return success


def sync_analytics() -> str | None:
    """Upload analytics.duckdb to Azure and return SAS URL."""
    print("\n" + "=" * 60)
    print("ğŸ“¤ STEP 2: Uploading to Azure Blob Storage")
    print("=" * 60)

    success = run_command([sys.executable, "-m", "scripts.cli", "sync", "--layer", "analytics"])

    if not success:
        return None

    # Read SAS URL from file
    url_file = Path("azure_analytics_url.txt")
    if not url_file.exists():
        print(f"\nâŒ SAS URL file not found: {url_file}")
        return None

    sas_url = url_file.read_text().strip()
    return sas_url


def print_instructions(sas_url: str):
    """Print instructions to update Streamlit Cloud secret."""
    print("\n" + "=" * 60)
    print("ğŸ“‹ STEP 3: Update Streamlit Cloud Secret")
    print("=" * 60)

    print("\n1. Go to your Streamlit Cloud app:")
    print("   https://share.streamlit.io/")

    print("\n2. Navigate to: Settings â†’ Secrets")

    print("\n3. Replace the old secret with this NEW one:")
    print("\n" + "â”€" * 60)
    print(f'db_download_url = "{sas_url}"')
    print("â”€" * 60)

    print("\n4. Click 'Save' (app will reboot automatically)")

    print("\n5. Wait ~2 minutes for:")
    print("   - App reboot")
    print("   - Download new database (165 MB)")
    print("   - Cache refresh")

    print("\n6. Access your dashboard - you should see TODAY's data! ğŸ‰")

    print("\n" + "=" * 60)
    print("âœ… Pipeline Complete!")
    print("=" * 60)

    print("\nğŸ’¡ Tip: Run this script daily after scraping to keep Streamlit updated")
    print("   python scripts/update_streamlit.py")


def main():
    parser = argparse.ArgumentParser(
        description="Update Streamlit Cloud dashboard with latest data"
    )
    parser.add_argument(
        "--skip-dbt",
        action="store_true",
        help="Skip DBT run (use if already executed)",
    )
    parser.add_argument(
        "--dbt-only",
        action="store_true",
        help="Only run DBT transformations (no Azure sync)",
    )
    args = parser.parse_args()

    print("\n" + "=" * 60)
    print("ğŸš€ Streamlit Cloud Update Pipeline")
    print("=" * 60)
    print(f"Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    # Step 1: DBT
    if not args.skip_dbt:
        if not run_dbt():
            print("\nâŒ DBT failed. Aborting.")
            sys.exit(1)
    else:
        print("\nâ© Skipping DBT (--skip-dbt flag)")

    if args.dbt_only:
        print("\nâœ… DBT complete. Exiting (--dbt-only flag)")
        sys.exit(0)

    # Step 2: Azure Sync
    sas_url = sync_analytics()
    if not sas_url:
        print("\nâŒ Azure sync failed. Aborting.")
        sys.exit(1)

    # Step 3: Instructions
    print_instructions(sas_url)

    print(f"\nFinished: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("\nğŸ¯ Next: Copy the URL above and update Streamlit Cloud secret!")


if __name__ == "__main__":
    main()
