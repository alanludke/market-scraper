"""
Final cleanup script - Remove generated files and fix remaining issues.

Actions:
1. Move htmlcov/ to tests/htmlcov/
2. Delete .pytest_cache/ and __pycache__/ from root
3. Check for src/scrapers/ duplicate (vs src/ingest/scrapers/)
4. Move market_data.duckdb to data/ (if exists and not gitignored)
5. Update .gitignore with generated files
6. Clean all __pycache__ directories in project

Usage:
    python scripts/final_cleanup.py --dry-run  # Preview
    python scripts/final_cleanup.py            # Execute
"""

import argparse
import shutil
from pathlib import Path
from loguru import logger

# Configure logger
logger.add(
    "data/logs/final_cleanup_{time}.log",
    rotation="10 MB",
    level="INFO",
    format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}"
)


class FinalCleanup:
    """Final cleanup operations."""

    def __init__(self, root: Path, dry_run: bool = False):
        self.root = root
        self.dry_run = dry_run
        self.actions = []

    def plan_cleanup(self) -> None:
        """Plan all cleanup actions."""

        # 1. Move htmlcov/ to tests/
        htmlcov_src = self.root / "htmlcov"
        htmlcov_dst = self.root / "tests/htmlcov"
        if htmlcov_src.exists():
            self.actions.append(("move", htmlcov_src, htmlcov_dst, "Coverage reports"))

        # 2. Delete .pytest_cache/ from root
        pytest_cache = self.root / ".pytest_cache"
        if pytest_cache.exists():
            self.actions.append(("delete", pytest_cache, None, "Generated pytest cache"))

        # 3. Delete __pycache__/ from root
        pycache = self.root / "__pycache__"
        if pycache.exists():
            self.actions.append(("delete", pycache, None, "Generated bytecode cache"))

        # 4. Check for src/scrapers/ duplicate
        scrapers_old = self.root / "src/scrapers"
        scrapers_new = self.root / "src/ingest/scrapers"
        if scrapers_old.exists() and scrapers_new.exists():
            self.actions.append(("check_duplicate", scrapers_old, scrapers_new, "Potential duplicate scrapers/"))

        # 5. Move market_data.duckdb to data/ (if not gitignored)
        duckdb_file = self.root / "market_data.duckdb"
        duckdb_dst = self.root / "data/market_data.duckdb"
        if duckdb_file.exists():
            self.actions.append(("move", duckdb_file, duckdb_dst, "DuckDB database"))

        # 6. Find all __pycache__ directories
        pycache_dirs = list(self.root.glob("**/__pycache__"))
        for pycache_dir in pycache_dirs:
            # Skip .venv and archive
            if ".venv" not in str(pycache_dir) and "archive" not in str(pycache_dir):
                self.actions.append(("delete", pycache_dir, None, f"Bytecode cache: {pycache_dir.relative_to(self.root)}"))

    def execute(self) -> None:
        """Execute cleanup actions."""
        logger.info("Starting final cleanup...")

        if not self.actions:
            logger.info("âœ… No cleanup needed - project is already clean!")
            return

        logger.info(f"\nðŸ“¦ Executing {len(self.actions)} cleanup actions...\n")

        for action_type, source, destination, description in self.actions:
            if action_type == "move":
                self._move(source, destination, description)
            elif action_type == "delete":
                self._delete(source, description)
            elif action_type == "check_duplicate":
                self._check_duplicate(source, destination, description)

        logger.info("\nâœ… Final cleanup complete!")

        if self.dry_run:
            logger.info("\nâ„¹ï¸  This was a DRY RUN - no changes were made")
            logger.info("Run without --dry-run to execute the cleanup")

    def _move(self, source: Path, destination: Path, description: str) -> None:
        """Move file or directory."""
        if not source.exists():
            logger.warning(f"âš ï¸  Source not found (skipping): {source}")
            return

        if self.dry_run:
            logger.info(f"[DRY RUN] Would move: {source.name} â†’ {destination}")
            logger.info(f"  {description}")
        else:
            destination.parent.mkdir(parents=True, exist_ok=True)
            shutil.move(str(source), str(destination))
            logger.info(f"âœ“ Moved: {source.name} â†’ {destination}")
            logger.info(f"  {description}")

    def _delete(self, path: Path, description: str) -> None:
        """Delete file or directory."""
        if not path.exists():
            logger.warning(f"âš ï¸  Path not found (skipping): {path}")
            return

        if self.dry_run:
            logger.info(f"[DRY RUN] Would delete: {path}")
            logger.info(f"  {description}")
        else:
            if path.is_dir():
                shutil.rmtree(path)
            else:
                path.unlink()
            logger.info(f"âœ“ Deleted: {path}")
            logger.info(f"  {description}")

    def _check_duplicate(self, old_path: Path, new_path: Path, description: str) -> None:
        """Check for duplicate directories."""
        logger.warning(f"\nâš ï¸  DUPLICATE FOUND: {description}")
        logger.warning(f"  Old: {old_path}")
        logger.warning(f"  New: {new_path}")

        # Count files in each
        old_files = list(old_path.glob("**/*.py")) if old_path.is_dir() else []
        new_files = list(new_path.glob("**/*.py")) if new_path.is_dir() else []

        logger.warning(f"  Old contains {len(old_files)} Python files")
        logger.warning(f"  New contains {len(new_files)} Python files")

        if len(old_files) == 0:
            logger.info(f"  â†’ Old directory is empty, safe to delete")
            if not self.dry_run:
                shutil.rmtree(old_path)
                logger.info(f"âœ“ Deleted empty duplicate: {old_path}")
        else:
            logger.warning(f"  â†’ MANUAL ACTION REQUIRED: Review and delete {old_path} if it's truly duplicate")

    def update_gitignore(self) -> None:
        """Update .gitignore with generated files."""
        gitignore_path = self.root / ".gitignore"

        if not gitignore_path.exists():
            logger.warning("âš ï¸  .gitignore not found!")
            return

        with open(gitignore_path, "r", encoding="utf-8") as f:
            content = f.read()

        # Patterns to add (if not already present)
        patterns_to_add = [
            "# Test coverage",
            "htmlcov/",
            "tests/htmlcov/",
            ".coverage",
            ".coverage.*",
            "",
            "# Pytest cache",
            ".pytest_cache/",
        ]

        # Check if patterns already exist
        needs_update = False
        for pattern in patterns_to_add:
            if pattern and pattern not in content:
                needs_update = True
                break

        if not needs_update:
            logger.info("âœ“ .gitignore already up to date")
            return

        if self.dry_run:
            logger.info("[DRY RUN] Would update .gitignore with:")
            for pattern in patterns_to_add:
                logger.info(f"  {pattern}")
        else:
            # Append new patterns
            with open(gitignore_path, "a", encoding="utf-8") as f:
                f.write("\n")
                for pattern in patterns_to_add:
                    f.write(f"{pattern}\n")

            logger.info("âœ“ Updated .gitignore with generated file patterns")

    def print_summary(self) -> None:
        """Print cleanup summary."""
        logger.info("\n" + "=" * 60)
        logger.info("FINAL CLEANUP PLAN")
        logger.info("=" * 60)
        for action_type, source, destination, description in self.actions:
            if action_type == "move":
                logger.info(f"â€¢ MOVE: {source.name} â†’ {destination}")
            elif action_type == "delete":
                logger.info(f"â€¢ DELETE: {source}")
            elif action_type == "check_duplicate":
                logger.info(f"â€¢ CHECK: {description}")
            logger.info(f"  {description}")
        logger.info("=" * 60)


def main():
    parser = argparse.ArgumentParser(description="Final cleanup")
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Preview changes without executing"
    )

    args = parser.parse_args()

    # Initialize cleanup
    root = Path.cwd()
    cleanup = FinalCleanup(root=root, dry_run=args.dry_run)

    # Plan cleanup
    cleanup.plan_cleanup()

    # Print summary
    cleanup.print_summary()

    # Execute
    cleanup.execute()

    # Update .gitignore
    cleanup.update_gitignore()

    if not args.dry_run:
        logger.info("\n" + "=" * 60)
        logger.info("NEXT STEPS")
        logger.info("=" * 60)
        logger.info("1. Verify everything still works:")
        logger.info("   python src/cli/scraper.py --help")
        logger.info("   streamlit run src/dashboard/app.py")
        logger.info("   pytest")
        logger.info("")
        logger.info("2. Commit changes:")
        logger.info("   git add .")
        logger.info("   git status")
        logger.info("   git commit -m 'Cleanup: Remove generated files and apply colocation'")
        logger.info("=" * 60)


if __name__ == "__main__":
    main()
